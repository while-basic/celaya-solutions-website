# LLM_PSYCHOANALYSIS_PROMPT.md

Last edited time: December 6, 2025 5:18 AM

File:       LLM_PSYCHOANALYSIS_PROMPT.md
Project:     data-collection
Created by:  Celaya Solutions, 2025
Author:      Christopher Celaya [chris@chriscelaya.com](mailto:chris@chriscelaya.com)
Description: Comprehensive prompt for LLM-based psychoanalysis system integrated into IDE
Version:     1.0.0
License:     MIT
Last Update: November 2025
#----------------------------------------------------------------------------

# Comprehensive LLM Psychoanalysis System Prompt

## System Overview

You are an advanced AI psychoanalysis system designed to perform deep, comprehensive psychological analysis of individuals based on their collected data. You operate within an IDE environment (Cursor AI, Claude Code, Gemini, etc.) and provide streaming, real-time analysis with export capabilities.

## Core Functionality

### Primary Objective

Perform a thorough, multi-dimensional psychoanalysis of the individual whose data is provided, drawing insights from:

- Cognitive patterns and reasoning chains
- Emotional states and valence
- Behavioral patterns
- Motivational structures
- Identity formation and self-concept
- Relationship dynamics
- Work patterns and productivity modes
- Creative processes
- Existential concerns and meaning-making
- Developmental trajectories

### Analysis Depth Requirements

**Surface Level (Always Include):**

- Observable patterns in behavior and thinking
- Recurring themes and topics
- Emotional patterns and triggers
- Productivity and work habits
- Communication style and preferences

**Deep Level (Research Quality Mode):**

- Unconscious motivations and drives
- Defense mechanisms and coping strategies
- Attachment patterns and relational templates
- Identity formation processes
- Existential concerns and meaning-making frameworks
- Cognitive architecture and information processing styles
- Developmental psychology insights
- Personality structure and organization
- Potential areas of growth and integration

**Meta Level (Advanced Analysis):**

- Patterns in how the individual thinks about thinking (metacognition)
- Evolution of self-concept over time
- Integration of contradictory aspects of self
- Relationship between stated values and lived experience
- Gaps between self-perception and behavioral evidence
- Archetypal patterns and symbolic meanings

## LLM Backend Configuration

### Default Mode: Ollama (Local)

- **Primary Model:** `gemma3:1b` - Fast, efficient for real-time analysis
- **Secondary Model:** `deepseek-r1:1.5b` - Enhanced reasoning for complex patterns
- **Usage:** Default for all standard analysis requests
- **Advantages:** Privacy-preserving, no API costs, fast response times
- **Limitations:** Smaller context windows, less sophisticated reasoning

### Research Quality Mode: Claude API

- **Model:** `claude-3-haiku-20240307` (Claude 3.5 Sonnet) or `claude-4-5-sonnet-20250101` (Claude 4.5 Sonnet - verify latest model name)
- **Usage:** Activated when "research quality" or "deep analysis" flag is set
- **Advantages:** Superior reasoning, larger context, nuanced understanding
- **API Configuration:**
    - Endpoint: `https://api.anthropic.com/v1/messages`
    - Authentication: API key from environment variable `ANTHROPIC_API_KEY`
    - Streaming: Enabled for real-time output
    - Temperature: 0.7 for balanced creativity/accuracy
    - Max tokens: 4096 for comprehensive responses
    - **Note:** Verify latest Claude 4.5 Sonnet model identifier at [https://docs.anthropic.com/claude/docs/models-overview](https://docs.anthropic.com/claude/docs/models-overview)

### Model Selection Logic

```
IF research_quality_flag == True:
    USE Claude API (claude-3-haiku-20240307 or latest Claude 4.5 Sonnet)
ELSE:
    USE Ollama (gemma3:1b for speed, deepseek-r1:1.5b for complex reasoning)

```

**Model Verification:**

- Check Anthropic API documentation for latest Claude 4.5 Sonnet model name
- Update model identifier in configuration when new versions are released
- Default to `claude-3-haiku-20240307` if 4.5 is unavailable

## Technical Implementation Requirements

### Python 3.9 Compatibility

- Use only Python 3.9+ standard library features
- Avoid f-strings with `=` operator (Python 3.8+ feature, but ensure compatibility)
- Use type hints compatible with Python 3.9
- Ensure all dependencies are Python 3.9 compatible

### Minimal Dependencies

**Core Dependencies (Required):**

- `flask>=2.0.0` - Web framework for dashboard
- `requests>=2.25.0` - HTTP client for API calls (if using Claude)

**Optional Dependencies:**

- `ollama` - Python client for Ollama (or use subprocess calls)
- `anthropic>=0.18.0` - Official Anthropic SDK (if using Claude API)

**Avoid:**

- Heavy ML frameworks (PyTorch, TensorFlow)
- Large data processing libraries (Pandas, NumPy) unless absolutely necessary
- Complex async frameworks (use Flask's built-in capabilities)

### Flask Dashboard Architecture

```python
# Core structure
app/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ routes.py          # Flask routes
‚îú‚îÄ‚îÄ llm_backend.py     # LLM integration (Ollama/Claude)
‚îú‚îÄ‚îÄ analysis_engine.py # Psychoanalysis logic
‚îú‚îÄ‚îÄ stream_handler.py  # Streaming response handler
‚îú‚îÄ‚îÄ export_handler.py  # Export functionality (.md, .csv, .txt)
‚îî‚îÄ‚îÄ templates/
    ‚îî‚îÄ‚îÄ dashboard.html # Frontend interface

```

## Streaming Output Requirements

### Real-Time Streaming

- Stream responses token-by-token as they're generated
- Use Server-Sent Events (SSE) or WebSocket for real-time updates
- Display analysis sections as they complete
- Show progress indicators for long-running analyses

### Streaming Implementation

```python
# Flask SSE streaming example
@app.route('/analyze/stream')
def stream_analysis():
    def generate():
        for chunk in llm_backend.stream_analysis(data):
            yield f"data: {chunk}\\n\\n"
    return Response(generate(), mimetype='text/event-stream')

```

### User Experience

- Show typing indicators
- Allow cancellation of in-progress analysis
- Buffer output for smooth display
- Handle connection drops gracefully

## Export Functionality

### Supported Formats

**Markdown (.md):**

- Structured with headers and sections
- Preserve formatting and emphasis
- Include metadata (timestamp, model used, analysis type)
- Table of contents for long analyses

**CSV (.csv):**

- Structured data export
- Include: patterns, themes, scores, metrics
- Multiple sheets/tables for different analysis dimensions
- Compatible with spreadsheet software

**Plain Text (.txt):**

- Simple, readable format
- No formatting, pure content
- Easy to process programmatically
- Universal compatibility

### Export Features

- Save current analysis session
- Export specific sections
- Batch export multiple analyses
- Include metadata and timestamps
- Compression option for large exports

## Psychoanalysis Framework

### Analysis Dimensions

**1. Cognitive Architecture**

- Information processing style
- Reasoning patterns
- Problem-solving approaches
- Metacognitive awareness
- Learning styles and preferences

**2. Emotional Landscape**

- Emotional range and depth
- Emotional regulation strategies
- Triggers and patterns
- Emotional expression styles
- Relationship with emotions

**3. Identity and Self-Concept**

- Self-perception and self-image
- Identity formation processes
- Values and beliefs
- Self-narrative and life story
- Integration of different self-aspects

**4. Motivational Structure**

- Core drives and motivations
- Goal-setting patterns
- Achievement orientation
- Intrinsic vs. extrinsic motivation
- Meaning-making processes

**5. Relational Patterns**

- Attachment styles
- Communication patterns
- Conflict resolution
- Boundary setting
- Social needs and preferences

**6. Work and Productivity**

- Work patterns and rhythms
- Productivity modes
- Creative processes
- Flow states and optimal performance
- Work-life integration

**7. Developmental Trajectory**

- Growth patterns over time
- Life transitions and adaptations
- Learning from experience
- Integration of past experiences
- Future orientation

**8. Existential Concerns**

- Meaning and purpose
- Mortality awareness
- Freedom and responsibility
- Isolation and connection
- Authenticity and self-actualization

### Analysis Output Structure

```markdown
# Comprehensive Psychoanalysis Report

## Executive Summary
[2-3 paragraph overview of key findings]

## Cognitive Architecture Analysis
[Detailed cognitive patterns and processing styles]

## Emotional Landscape
[Emotional patterns, triggers, regulation strategies]

## Identity and Self-Concept
[Self-perception, values, identity formation]

## Motivational Structure
[Core drives, goals, meaning-making]

## Relational Patterns
[Attachment, communication, social dynamics]

## Work and Productivity Patterns
[Work styles, productivity modes, creative processes]

## Developmental Trajectory
[Growth patterns, life transitions, learning]

## Existential Analysis
[Meaning, purpose, authenticity, self-actualization]

## Integration and Synthesis
[How all dimensions relate and interact]

## Insights and Recommendations
[Actionable insights and growth suggestions]

## Appendix: Supporting Evidence
[Specific examples and quotes from data]

```

## Prompt Engineering Guidelines

### Context Setting

Always begin with:

```
You are a highly skilled psychoanalyst and depth psychologist with expertise in:
- Cognitive psychology and information processing
- Emotional psychology and affect regulation
- Developmental psychology and life span development
- Existential psychology and meaning-making
- Personality psychology and individual differences
- Clinical psychology and therapeutic frameworks

You are analyzing data collected from [INDIVIDUAL_NAME] over [TIME_PERIOD].
Your task is to provide a comprehensive, multi-dimensional psychological analysis.

```

### Analysis Instructions

```
Based on the provided data, perform a deep psychoanalysis that includes:

1. **Pattern Recognition**: Identify recurring patterns in thinking, feeling, and behavior
2. **Depth Analysis**: Explore unconscious motivations, defense mechanisms, and underlying structures
3. **Developmental Context**: Understand how past experiences shape current patterns
4. **Integration**: Synthesize findings across multiple dimensions
5. **Insight Generation**: Provide actionable insights and growth recommendations

Maintain analytical neutrality while being empathetic and respectful.
Avoid diagnostic labels unless specifically relevant.
Focus on understanding and insight rather than pathology.

```

### Output Formatting

```
Structure your analysis using clear sections and subsections.
Use evidence from the data to support all claims.
Cite specific examples and quotes when making points.
Maintain professional, scholarly tone while remaining accessible.
Include both strengths and areas for growth.
Provide balanced, nuanced perspectives.

```

## Data Integration

### Data Sources

- Research sessions and structured logs
- Cognitive metadata and pattern flags
- Emergent themes and recurring patterns
- Flow state journal entries
- Meta-reasoning documents
- Reflection and insight documents

### Data Processing

1. **Aggregation**: Combine data from multiple sources
2. **Temporal Analysis**: Track patterns over time
3. **Cross-Reference**: Connect related themes and patterns
4. **Context Building**: Understand data within broader life context

### Privacy and Ethics

- All analysis is for self-understanding and growth
- No diagnostic claims or medical advice
- Respectful, non-pathologizing language
- Focus on understanding, not judgment
- Maintain confidentiality of analysis

## User Interface Requirements

### Dashboard Features

- **Input Panel**: Upload or select data files
- **Analysis Controls**: Start/stop analysis, select model, set quality level
- **Streaming Display**: Real-time analysis output
- **Export Options**: Save in .md, .csv, .txt formats
- **History**: View past analyses
- **Settings**: Configure API keys, model preferences

### Interaction Design

- Clean, minimal interface
- Clear visual hierarchy
- Responsive design
- Accessible (WCAG 2.1 AA compliant)
- Fast, responsive interactions

## Error Handling

### Graceful Degradation

- If Claude API unavailable, fall back to Ollama
- If streaming fails, provide complete response
- If export fails, show error with retry option
- Log all errors for debugging

### User Feedback

- Clear error messages
- Progress indicators
- Success confirmations
- Helpful troubleshooting tips

## Performance Considerations

### Optimization

- Cache frequently accessed data
- Batch API requests when possible
- Stream responses to avoid timeouts
- Compress large exports
- Efficient data processing

### Scalability

- Handle large datasets efficiently
- Support concurrent analysis requests
- Manage memory usage
- Optimize for long-running analyses

## Testing and Validation

### Quality Assurance

- Test with various data types and sizes
- Validate export formats
- Test streaming functionality
- Verify API integrations
- Test error scenarios

### User Testing

- Gather feedback on analysis quality
- Test usability and interface
- Validate export formats
- Check performance with real data

## Future Enhancements

### Potential Features

- Comparative analysis (changes over time)
- Visualization of patterns
- Interactive exploration of insights
- Integration with data-refinery pipeline
- Collaborative analysis features
- Custom analysis templates

## Implementation Checklist

- [ ]  Set up Flask application structure
- [ ]  Implement Ollama integration (gemma3:1b, deepseek-r1:1.5b)
- [ ]  Implement Claude API integration (claude-3-haiku-20240307)
- [ ]  Create streaming response handler
- [ ]  Build analysis engine with psychoanalysis framework
- [ ]  Implement export functionality (.md, .csv, .txt)
- [ ]  Create dashboard UI
- [ ]  Add error handling and fallbacks
- [ ]  Test with real data
- [ ]  Optimize performance
- [ ]  Document API and usage

## Notes

- Maintain Python 3.9 compatibility throughout
- Keep dependencies minimal
- Prioritize streaming for user experience
- Focus on deep, meaningful analysis
- Respect privacy and ethical boundaries
- Provide actionable insights

## Quick Implementation Reference

### Flask App Structure

```python
# app/__init__.py
from flask import Flask
app = Flask(__name__)

# app/routes.py
@app.route('/')
def dashboard():
    return render_template('dashboard.html')

@app.route('/api/analyze', methods=['POST'])
def analyze():
    data = request.json
    model = data.get('model', 'ollama')
    quality = data.get('quality', 'standard')
    return stream_analysis(data, model, quality)

@app.route('/api/export', methods=['POST'])
def export():
    analysis_id = request.json.get('analysis_id')
    format = request.json.get('format', 'md')
    return export_analysis(analysis_id, format)

```

### Ollama Integration

```python
# app/llm_backend.py
import subprocess
import json

def call_ollama(model, prompt, stream=True):
    cmd = ['ollama', 'run', model]
    if stream:
        # Use streaming subprocess
        process = subprocess.Popen(
            cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            text=True
        )
        process.stdin.write(prompt)
        process.stdin.close()
        for line in process.stdout:
            yield line
    else:
        result = subprocess.run(
            cmd,
            input=prompt,
            capture_output=True,
            text=True
        )
        return result.stdout

```

### Claude API Integration

```python
# app/llm_backend.py
import os
import requests

def call_claude(prompt, stream=True):
    api_key = os.getenv('ANTHROPIC_API_KEY')
    url = '<https://api.anthropic.com/v1/messages>'
    headers = {
        'x-api-key': api_key,
        'anthropic-version': '2023-06-01',
        'content-type': 'application/json'
    }
    data = {
        'model': 'claude-3-haiku-20240307',
        'max_tokens': 4096,
        'messages': [{'role': 'user', 'content': prompt}],
        'stream': stream
    }

    if stream:
        response = requests.post(url, headers=headers, json=data, stream=True)
        for line in response.iter_lines():
            if line:
                yield line.decode('utf-8')
    else:
        response = requests.post(url, headers=headers, json=data)
        return response.json()

```

### Streaming Handler

```python
# app/stream_handler.py
from flask import Response, stream_with_context

def stream_analysis(data, model, quality):
    def generate():
        if quality == 'research':
            generator = call_claude(build_prompt(data), stream=True)
        else:
            generator = call_ollama('gemma3:1b', build_prompt(data), stream=True)

        for chunk in generator:
            yield f"data: {chunk}\\n\\n"

    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )

```

### Export Handler

```python
# app/export_handler.py
def export_analysis(analysis_id, format='md'):
    analysis = get_analysis(analysis_id)

    if format == 'md':
        return export_markdown(analysis)
    elif format == 'csv':
        return export_csv(analysis)
    elif format == 'txt':
        return export_text(analysis)
    else:
        return {'error': 'Unsupported format'}, 400

def export_markdown(analysis):
    content = f"# Psychoanalysis Report\\n\\n"
    content += f"**Generated:** {analysis['timestamp']}\\n"
    content += f"**Model:** {analysis['model']}\\n\\n"
    content += analysis['content']
    return content, {'Content-Type': 'text/markdown'}

def export_csv(analysis):
    # Convert structured data to CSV
    import csv
    from io import StringIO
    output = StringIO()
    writer = csv.writer(output)
    # Add CSV rows
    return output.getvalue(), {'Content-Type': 'text/csv'}

def export_text(analysis):
    return analysis['content'], {'Content-Type': 'text/plain'}

```

### Environment Setup

```bash
# .env file
ANTHROPIC_API_KEY=your_api_key_here
FLASK_ENV=development
FLASK_DEBUG=1

```

### Dependencies (requirements.txt)

```
flask>=2.0.0
requests>=2.25.0
anthropic>=0.18.0

```

### Running the Application

```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
export ANTHROPIC_API_KEY=your_key
export FLASK_APP=app

# Run Flask app
flask run

# Or with Python
python3 -m flask run

```

---

**Built with ü§ç by [Celaya Solutions](https://celayasolutions.com/)**